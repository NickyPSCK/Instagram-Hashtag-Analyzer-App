{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd098e0e5a8360ea46c4d89f3d13cddee7b000a2354652bb761e304bf1406e0af16",
   "display_name": "Python 3.8.5 64-bit ('INDEPENDENT-STUDY': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "# At least OpenCV 4.4.0 is required to run YOLOv4\n",
    "\n",
    "\n",
    "# Load a pre-trained YOLOv3 model from disk\n",
    "net = cv2.dnn.readNetFromDarknet(\"model/YOLO-COCO/yolov4.cfg\",\"model/YOLO-COCO/yolov4.weights\")\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)        \n",
    "# Determine only the output layer names that we need from YOLO\n",
    "olayer_name = net.getLayerNames()\n",
    "#print( olayer_name )\n",
    "olayer_name = [ olayer_name[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "\n",
    "# Input Image BGR\n",
    "capture = cv2.VideoCapture(0)\n",
    "ret,frame = capture.read()\n",
    "capture.release()\n",
    "\n",
    "# Create a 4D blob from a frame a a preprocessing step\n",
    "# This function includes options to do\n",
    "# - mean subtraction\n",
    "# - resize or scale values by scalefactor\n",
    "# - crop (from center)\n",
    "# - swap blue and red channels\n",
    "# Be careful, each model requires different preprocessing!!!\n",
    "(h,w) = frame.shape[:2]\n",
    "\n",
    "yolo_imgW = 416             # width of the network input image\n",
    "yolo_imgH = 416             # height of the network input image\n",
    "blob = cv2.dnn.blobFromImage( frame,\n",
    "                                1 / 255.0,                # scaleFactor\n",
    "                                (yolo_imgW, yolo_imgH),   # spatial size of the CNN\n",
    "                                swapRB=True, crop=False)\n",
    "\n",
    "# Pass the blob to the network\n",
    "net.setInput(blob)\n",
    "outputs = net.forward(olayer_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.3059810e-02, 1.6438799e-02, 2.8836997e-02, 3.8010102e-02,\n",
       "       1.8340777e-05, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "outputs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # Lists to store detected bounding boxes, confidences and classIDs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "\n",
    "    # Loop over each of the layer outputs\n",
    "    for output in outputs:\n",
    "        # Loop over each of the detections\n",
    "        for detection in output:\n",
    "            # Extract the confidence (i.e., probability) and classID\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # Filter out weak detections by ensuring the confidence is greater than the threshold\n",
    "            if confidence > 0:\n",
    "\n",
    "\n",
    "                # Compute the (x, y)-coordinates of the bounding box\n",
    "                box = detection[0:4] * np.array( [w,h,w,h] )\n",
    "                (centerX, centerY, width, height) = box.astype('int')\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # Add a new bounding box to our list\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "    boxes\n",
    "\n",
    "return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[-14, 132, 596, 350],\n",
       " [-13, 132, 595, 349],\n",
       " [12, 131, 628, 351],\n",
       " [17, 132, 618, 350],\n",
       " [57, 130, 597, 352],\n",
       " [59, 129, 593, 353]]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.23407423496246338,\n",
       " 0.2557812035083771,\n",
       " 0.9193888902664185,\n",
       " 0.9289783835411072,\n",
       " 0.70229572057724,\n",
       " 0.7005264163017273]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for YOLOv3\n",
    "confident_constant = 0.5    # confidence threshold\n",
    "threshold_constant = 0.3    # non-maxium suppression threshold\n",
    "\n",
    "idxs = cv2.dnn.NMSBoxes(boxes, confidences, confident_constant, threshold_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "idxs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-14, 132, 596, 350],\n",
       "       [-13, 132, 595, 349],\n",
       "       [ 12, 131, 628, 351],\n",
       "       [ 17, 132, 618, 350],\n",
       "       [ 57, 130, 597, 352],\n",
       "       [ 59, 129, 593, 353]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "np.array(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.23407423496246338,\n",
       " 0.2557812035083771,\n",
       " 0.9193888902664185,\n",
       " 0.9289783835411072,\n",
       " 0.70229572057724,\n",
       " 0.7005264163017273]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "classIDs"
   ]
  }
 ]
}