{
 "cells": [
  {
   "source": [
    "# Example of Class RatinaNetPrediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.init_sys import InitSystem\n",
    "from predictor import RatinaNetPrediction, load_images\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "InitSystem().init()\n",
    "\n",
    "with open('config/class.json', 'r') as f:\n",
    "    class_label = json.loads(f.read())\n",
    "\n",
    "X, path = load_images('static/downloads/hashtag/demo/demo2/*.jpg', color_mode='rgb', target_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "[('cup', 'mouse', 'tv', 'laptop', 'laptop'), ('person', 'tie'), ('mouse', 'tv'), ('mouse', 'laptop', 'tv'), ('dog',), ('dog',)]\n"
     ]
    }
   ],
   "source": [
    "odp = RatinaNetPrediction(\n",
    "                                    model_path='model/object_detection.h5',\n",
    "                                    class_label=class_label['object_detection_label'] \n",
    "                                    )\n",
    "prediction = odp.predict(X)\n",
    "print(odp.decode_predictions(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([[[   3,  507,  152,  640],\n",
       "         [ 698,  651,  826,  748],\n",
       "         [  96,  124,  722,  436],\n",
       "         ...,\n",
       "         [  -1,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,   -1]],\n",
       " \n",
       "        [[ 629,   10, 1326,  774],\n",
       "         [ 773,  285,  895,  428],\n",
       "         [ 782,  442,  950,  794],\n",
       "         ...,\n",
       "         [ 263,  373,  823,  715],\n",
       "         [  92,   42,  343,  269],\n",
       "         [   4,  348,  293,  758]],\n",
       " \n",
       "        [[  77,  624,  207,  814],\n",
       "         [ 299,   23,  641,  508],\n",
       "         [ 280,   13,  720, 1061],\n",
       "         ...,\n",
       "         [  -1,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,   -1]],\n",
       " \n",
       "        [[ 723,  414,  788,  453],\n",
       "         [ 521,  431,  712,  494],\n",
       "         [ 169,  295,  495,  541],\n",
       "         ...,\n",
       "         [ 442,  341,  492,  433],\n",
       "         [ 725,  415,  788,  452],\n",
       "         [ 302,  117,  901,  380]],\n",
       " \n",
       "        [[   5,  250,  590,  985],\n",
       "         [  12,  241,  582,  985],\n",
       "         [  13,  640,  588,  982],\n",
       "         ...,\n",
       "         [  -1,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,   -1]],\n",
       " \n",
       "        [[  16,   55,  763,  803],\n",
       "         [ 254,  611,  438,  791],\n",
       "         [ 239,  569,  477,  785],\n",
       "         ...,\n",
       "         [  -1,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,   -1]]]),\n",
       " array([[ 0.9744698 ,  0.97295094,  0.8666487 , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.8763897 ,  0.5413894 ,  0.5158895 , ...,  0.06539735,\n",
       "          0.06537813,  0.06530905],\n",
       "        [ 0.6852933 ,  0.568608  ,  0.38717043, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.9806912 ,  0.95963013,  0.9098865 , ...,  0.05491826,\n",
       "          0.0547713 ,  0.05463165],\n",
       "        [ 0.78194916,  0.31392914,  0.21733308, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.9444479 ,  0.49449265,  0.15634453, ..., -1.        ,\n",
       "         -1.        , -1.        ]], dtype=float32),\n",
       " array([[41, 64, 62, ..., -1, -1, -1],\n",
       "        [ 0, 54, 27, ..., 45, 54, 52],\n",
       "        [64, 62, 63, ..., -1, -1, -1],\n",
       "        [64, 66, 63, ...,  9, 67, 73],\n",
       "        [16, 15, 15, ..., -1, -1, -1],\n",
       "        [16, 32, 29, ..., -1, -1, -1]])]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}